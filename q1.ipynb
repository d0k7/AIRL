{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1) Checks GPU, sets deterministic seeds, imports PyTorch/torchvision u**"
      ],
      "metadata": {
        "id": "Ev8yac-Ofnlc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLiHWFOiexQs",
        "outputId": "2d6f5904-c115-42ef-9b63-ca2fd2dcda37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# @title Q1: Setup & Imports (GPU check + seeds)\n",
        "import os, math, time, random, json\n",
        "from dataclasses import dataclass, asdict\n",
        "import numpy as np\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "assert torch.cuda.is_available(), \"Enable GPU: Runtime > Change runtime type > GPU\"\n",
        "device = torch.device(\"cuda\")\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True  # speed on fixed-size batches\n",
        "seed_all(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Centralizes all tunables; choosepreset=\"strong\"for\"fast\"if**"
      ],
      "metadata": {
        "id": "zRo3civ4gIvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Q1: Config (switch preset to 'fast' if needed)\n",
        "@dataclass\n",
        "class CFG:\n",
        "    # data\n",
        "    num_classes: int = 10\n",
        "    img_size: int = 32\n",
        "\n",
        "    # model (good for CIFAR-10 on T4)\n",
        "    patch_size: int = 4\n",
        "    embed_dim: int = 384\n",
        "    depth: int = 8\n",
        "    num_heads: int = 6\n",
        "    mlp_ratio: float = 4.0\n",
        "    drop_rate: float = 0.1\n",
        "    attn_drop_rate: float = 0.0\n",
        "    drop_path_rate: float = 0.1\n",
        "\n",
        "    # training\n",
        "    epochs: int = 100\n",
        "    batch_size: int = 256\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 0.05\n",
        "    warmup_epochs: int = 5\n",
        "    label_smoothing: float = 0.1\n",
        "    mixup_alpha: float = 0.2\n",
        "    ema_decay: float = 0.999\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "    # misc\n",
        "    num_workers: int = 2\n",
        "    amp: bool = True                  # mixed precision\n",
        "    amp_dtype: torch.dtype = torch.float16  # T4 prefers fp16 (bf16 not supported on T4)\n",
        "    tta: bool = False                 # simple flip TTA at test time\n",
        "\n",
        "def make_cfg(preset=\"strong\"):\n",
        "    c = CFG()\n",
        "    if preset == \"fast\":\n",
        "        c.embed_dim = 256\n",
        "        c.depth = 6\n",
        "        c.num_heads = 4\n",
        "        c.batch_size = 256\n",
        "        c.epochs = 50\n",
        "        c.drop_path_rate = 0.05\n",
        "    return c\n",
        "\n",
        "cfg = make_cfg(\"strong\")\n",
        "print(cfg)\n"
      ],
      "metadata": {
        "id": "3ruidtaZf1NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19045bfc-2455-41f6-ab98-05c6795afc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CFG(num_classes=10, img_size=32, patch_size=4, embed_dim=384, depth=8, num_heads=6, mlp_ratio=4.0, drop_rate=0.1, attn_drop_rate=0.0, drop_path_rate=0.1, epochs=100, batch_size=256, lr=0.0003, weight_decay=0.05, warmup_epochs=5, label_smoothing=0.1, mixup_alpha=0.2, ema_decay=0.999, grad_clip=1.0, num_workers=2, amp=True, amp_dtype=torch.float16, tta=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Q1: Data & Augmentations\n",
        "MEAN = (0.4914, 0.4822, 0.4465)\n",
        "STD  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomCrop(cfg.img_size, padding=4, padding_mode='reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02,0.2), ratio=(0.3,3.3), value='random')\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "root = \"./data\"\n",
        "train_set = datasets.CIFAR10(root, train=True, download=True, transform=train_tfms)\n",
        "test_set  = datasets.CIFAR10(root, train=False, download=True, transform=test_tfms)\n",
        "\n",
        "def mixup_batch(x, y, alpha):\n",
        "    if alpha <= 0:\n",
        "        return x, F.one_hot(y, cfg.num_classes).float(), 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
        "    y1 = F.one_hot(y, cfg.num_classes).float()\n",
        "    y2 = F.one_hot(y[idx], cfg.num_classes).float()\n",
        "    mixed_y = lam * y1 + (1 - lam) * y2\n",
        "    return mixed_x, mixed_y, lam\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True,\n",
        "                          num_workers=cfg.num_workers, pin_memory=True, drop_last=True)\n",
        "test_loader  = DataLoader(test_set,  batch_size=512, shuffle=False,\n",
        "                          num_workers=cfg.num_workers, pin_memory=True)\n",
        "print(f\"train={len(train_set)} images, test={len(test_set)} images\")\n"
      ],
      "metadata": {
        "id": "ZWxGQrI6jNjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16abdf32-84dd-46cf-f275-254c9081264a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:14<00:00, 11.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train=50000 images, test=10000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3)  Pre-LN blocks, residuals, MHSA + MLP; stochastic depth (DropPath).**"
      ],
      "metadata": {
        "id": "xEDSDZy6wfOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Q1: ViT model (patchify, CLS, pos-emb, MHSA+MLP blocks)\n",
        "class DropPath(nn.Module):\n",
        "    def __init__(self, drop_prob=0.0):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "    def forward(self, x):\n",
        "        if self.drop_prob == 0.0 or not self.training: return x\n",
        "        keep = 1 - self.drop_prob\n",
        "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "        return x * (torch.rand(shape, device=x.device) < keep) / keep\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size, patch_size, in_chans=3, embed_dim=384):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "    def forward(self, x):                  # B,C,H,W\n",
        "        x = self.proj(x)                   # B,E,H',W'\n",
        "        x = x.flatten(2).transpose(1,2)    # B,N,E\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, mlp_ratio=4.0, drop=0.0):\n",
        "        super().__init__()\n",
        "        h = int(dim * mlp_ratio)\n",
        "        self.fc1 = nn.Linear(dim, h)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(h, dim)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x); x = self.act(x); x = self.drop(x)\n",
        "        x = self.fc2(x); x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, attn_drop=0.0, proj_drop=0.0):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = (dim // heads) ** -0.5\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.heads, C // self.heads).permute(2,0,3,1,4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2,-1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "        x = attn @ v\n",
        "        x = x.transpose(1,2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, heads, mlp_ratio, drop=0.0, attn_drop=0.0, drop_path=0.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn  = Attention(dim, heads, attn_drop, drop)\n",
        "        self.drop_path = DropPath(drop_path)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp   = MLP(dim, mlp_ratio, drop)\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, img_size, patch_size, in_chans, num_classes,\n",
        "                 embed_dim, depth, num_heads, mlp_ratio,\n",
        "                 drop_rate, attn_drop_rate, drop_path_rate):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        n = self.patch_embed.num_patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1,1,embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, n+1, embed_dim))\n",
        "        self.pos_drop  = nn.Dropout(drop_rate)\n",
        "\n",
        "        dpr = torch.linspace(0, drop_path_rate, steps=depth).tolist()\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(embed_dim, num_heads, mlp_ratio, drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i])\n",
        "            for i in range(depth)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        self.apply(self._init)\n",
        "\n",
        "    @staticmethod\n",
        "    def _init(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.zeros_(m.bias); nn.init.ones_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)              # B,N,C\n",
        "        B, N, C = x.shape\n",
        "        cls = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1)       # B,N+1,C\n",
        "        x = x + self.pos_embed[:, :N+1, :]\n",
        "        x = self.pos_drop(x)\n",
        "        for blk in self.blocks: x = blk(x)\n",
        "        x = self.norm(x)\n",
        "        return self.head(x[:,0])\n"
      ],
      "metadata": {
        "id": "vyHHG9w9wDlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Q1: Loss, EMA, Scheduler, Metrics\n",
        "class SoftCELoss(nn.Module):\n",
        "    def __init__(self, smoothing=0.0):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "    def forward(self, logits, target):  # target: hard labels or one-hot\n",
        "        if target.ndim == 1:\n",
        "            target = F.one_hot(target, logits.size(-1)).float()\n",
        "        if self.smoothing > 0:\n",
        "            target = target * (1 - self.smoothing) + self.smoothing / target.size(-1)\n",
        "        logp = F.log_softmax(logits, dim=-1)\n",
        "        return (-target * logp).sum(dim=-1).mean()\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {k: v.detach().clone() for k,v in model.state_dict().items()}\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        if self.decay <= 0: return\n",
        "        for k, v in model.state_dict().items():\n",
        "            if v.dtype.is_floating_point:\n",
        "                self.shadow[k].mul_(self.decay).add_(v, alpha=1-self.decay)\n",
        "    def copy_to(self, model):\n",
        "        for k, v in self.shadow.items():\n",
        "            if k in model.state_dict():\n",
        "                model.state_dict()[k].copy_(v)\n",
        "\n",
        "class WarmupCosine(torch.optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, warmup_steps, total_steps, last_epoch=-1):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.total_steps = total_steps\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "    def get_lr(self):\n",
        "        step = self.last_epoch + 1\n",
        "        if step < self.warmup_steps:\n",
        "            return [base * step / max(1, self.warmup_steps) for base in self.base_lrs]\n",
        "        t = (step - self.warmup_steps) / max(1, self.total_steps - self.warmup_steps)\n",
        "        scale = 0.5 * (1 + math.cos(math.pi * t))\n",
        "        return [base * scale for base in self.base_lrs]\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(logits, y):\n",
        "    return (logits.argmax(1) == y).float().mean().item()\n"
      ],
      "metadata": {
        "id": "nOdSUORXwlyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) full loop with MixUp, gradient clip, scheduler, best checkpoint, optional TTA.**"
      ],
      "metadata": {
        "id": "d_PUXjoLwzE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Q1: Train & Evaluate (saves best_vit_cifar10.pth and q1_results.json)\n",
        "\n",
        "# Define the model, optimizer, and other utilities for training\n",
        "model = VisionTransformer(\n",
        "    img_size=cfg.img_size, patch_size=cfg.patch_size, in_chans=3, num_classes=cfg.num_classes,\n",
        "    embed_dim=cfg.embed_dim, depth=cfg.depth, num_heads=cfg.num_heads, mlp_ratio=cfg.mlp_ratio,\n",
        "    drop_rate=cfg.drop_rate, attn_drop_rate=cfg.attn_drop_rate, drop_path_rate=cfg.drop_path_rate\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "criterion = SoftCELoss(smoothing=cfg.label_smoothing)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n",
        "ema = EMA(model, decay=cfg.ema_decay) if cfg.ema_decay > 0 else None\n",
        "\n",
        "total_steps = cfg.epochs * len(train_loader)\n",
        "warmup_steps = cfg.warmup_epochs * len(train_loader)\n",
        "sched = WarmupCosine(optimizer, warmup_steps=warmup_steps, total_steps=total_steps)\n",
        "\n",
        "best_acc, history = 0.0, []\n",
        "\n",
        "def eval_model(eval_m):\n",
        "    eval_m.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.autocast(device_type='cuda', dtype=cfg.amp_dtype, enabled=cfg.amp):\n",
        "                logits = eval_m(x)\n",
        "                if cfg.tta:\n",
        "                    logits_flip = eval_m(torch.flip(x, dims=[3]))\n",
        "                    logits = 0.5 * (logits + logits_flip)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(cfg.epochs):\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    run_loss = run_acc = 0.0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        x, y_mix, _ = mixup_batch(x, y, cfg.mixup_alpha)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type='cuda', dtype=cfg.amp_dtype, enabled=cfg.amp):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y_mix)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if cfg.grad_clip > 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        sched.step()\n",
        "        if ema: ema.update(model)\n",
        "\n",
        "        run_loss += loss.item()\n",
        "        run_acc  += accuracy(logits.detach(), torch.argmax(y_mix, dim=1))\n",
        "\n",
        "    # EMA copy for eval\n",
        "    if ema:\n",
        "        shadow_model = VisionTransformer(cfg.img_size, cfg.patch_size, 3, cfg.num_classes,\n",
        "                                        cfg.embed_dim, cfg.depth, cfg.num_heads, cfg.mlp_ratio,\n",
        "                                        cfg.drop_rate, cfg.attn_drop_rate, cfg.drop_path_rate).to(device)\n",
        "        shadow_model.load_state_dict(model.state_dict())\n",
        "        ema.copy_to(shadow_model)\n",
        "        val_acc = eval_model(shadow_model)\n",
        "        del shadow_model\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        val_acc = eval_model(model)\n",
        "\n",
        "    ep_loss = run_loss / len(train_loader)\n",
        "    ep_acc  = run_acc  / len(train_loader)\n",
        "    history.append({\"epoch\": epoch+1, \"train_loss\": ep_loss, \"train_acc\": ep_acc, \"val_acc\": val_acc})\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save({\"model\": model.state_dict(), \"cfg\": asdict(cfg), \"best_val_acc\": best_acc}, \"best_vit_cifar10.pth\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1:03d}/{cfg.epochs} | loss {ep_loss:.4f} | train_acc {ep_acc:.3f} \"\n",
        "          f\"| val_acc {val_acc:.4f} | best {best_acc:.4f} | {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Convert `cfg` object to dictionary and ensure that `dtype` is serializable (as a string)\n",
        "cfg_dict = asdict(cfg)\n",
        "cfg_dict['amp_dtype'] = str(cfg.amp_dtype)  # Convert dtype to string\n",
        "\n",
        "# Save the results in JSON format\n",
        "with open(\"q1_results.json\", \"w\") as f:\n",
        "    json.dump({\"best_test_acc\": best_acc, \"history\": history, \"cfg\": cfg_dict}, f, indent=2)\n",
        "\n",
        "print(\"✅ Best test accuracy:\", f\"{best_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "uaGws4NUwuzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64488a0-4a53-4cdd-f29f-4cc0f1c81e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-309477539.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001/100 | loss 2.1820 | train_acc 0.205 | val_acc 0.1619 | best 0.1619 | 59.0s\n",
            "Epoch 002/100 | loss 2.0464 | train_acc 0.287 | val_acc 0.2852 | best 0.2852 | 56.8s\n",
            "Epoch 003/100 | loss 1.9244 | train_acc 0.356 | val_acc 0.3144 | best 0.3144 | 58.0s\n",
            "Epoch 004/100 | loss 1.8727 | train_acc 0.395 | val_acc 0.3437 | best 0.3437 | 58.1s\n",
            "Epoch 005/100 | loss 1.8025 | train_acc 0.430 | val_acc 0.3915 | best 0.3915 | 58.4s\n",
            "Epoch 006/100 | loss 1.7579 | train_acc 0.453 | val_acc 0.4367 | best 0.4367 | 57.5s\n",
            "Epoch 007/100 | loss 1.7238 | train_acc 0.471 | val_acc 0.4823 | best 0.4823 | 57.7s\n",
            "Epoch 008/100 | loss 1.7220 | train_acc 0.475 | val_acc 0.5209 | best 0.5209 | 57.4s\n",
            "Epoch 009/100 | loss 1.6813 | train_acc 0.498 | val_acc 0.5489 | best 0.5489 | 59.8s\n",
            "Epoch 010/100 | loss 1.6490 | train_acc 0.514 | val_acc 0.5788 | best 0.5788 | 58.2s\n",
            "Epoch 011/100 | loss 1.6584 | train_acc 0.517 | val_acc 0.6008 | best 0.6008 | 57.9s\n",
            "Epoch 012/100 | loss 1.6179 | train_acc 0.530 | val_acc 0.6206 | best 0.6206 | 59.0s\n",
            "Epoch 013/100 | loss 1.5980 | train_acc 0.544 | val_acc 0.6385 | best 0.6385 | 59.1s\n",
            "Epoch 014/100 | loss 1.5874 | train_acc 0.549 | val_acc 0.6521 | best 0.6521 | 59.0s\n",
            "Epoch 015/100 | loss 1.5483 | train_acc 0.563 | val_acc 0.6630 | best 0.6630 | 58.1s\n",
            "Epoch 016/100 | loss 1.5508 | train_acc 0.569 | val_acc 0.6738 | best 0.6738 | 58.4s\n",
            "Epoch 017/100 | loss 1.5235 | train_acc 0.581 | val_acc 0.6842 | best 0.6842 | 58.8s\n",
            "Epoch 018/100 | loss 1.5036 | train_acc 0.592 | val_acc 0.6926 | best 0.6926 | 58.7s\n",
            "Epoch 019/100 | loss 1.5135 | train_acc 0.593 | val_acc 0.6996 | best 0.6996 | 57.4s\n",
            "Epoch 020/100 | loss 1.4798 | train_acc 0.600 | val_acc 0.7076 | best 0.7076 | 58.9s\n",
            "Epoch 021/100 | loss 1.4557 | train_acc 0.616 | val_acc 0.7148 | best 0.7148 | 58.5s\n",
            "Epoch 022/100 | loss 1.4828 | train_acc 0.608 | val_acc 0.7231 | best 0.7231 | 58.4s\n",
            "Epoch 023/100 | loss 1.4767 | train_acc 0.617 | val_acc 0.7319 | best 0.7319 | 57.3s\n",
            "Epoch 024/100 | loss 1.4435 | train_acc 0.628 | val_acc 0.7362 | best 0.7362 | 58.1s\n",
            "Epoch 025/100 | loss 1.4563 | train_acc 0.624 | val_acc 0.7411 | best 0.7411 | 58.3s\n",
            "Epoch 026/100 | loss 1.4685 | train_acc 0.620 | val_acc 0.7472 | best 0.7472 | 57.9s\n",
            "Epoch 027/100 | loss 1.4104 | train_acc 0.653 | val_acc 0.7539 | best 0.7539 | 57.0s\n",
            "Epoch 028/100 | loss 1.3813 | train_acc 0.653 | val_acc 0.7603 | best 0.7603 | 58.2s\n",
            "Epoch 029/100 | loss 1.3916 | train_acc 0.653 | val_acc 0.7650 | best 0.7650 | 58.0s\n",
            "Epoch 030/100 | loss 1.3665 | train_acc 0.660 | val_acc 0.7710 | best 0.7710 | 57.8s\n",
            "Epoch 031/100 | loss 1.3754 | train_acc 0.665 | val_acc 0.7752 | best 0.7752 | 56.8s\n",
            "Epoch 032/100 | loss 1.3979 | train_acc 0.664 | val_acc 0.7813 | best 0.7813 | 57.4s\n",
            "Epoch 033/100 | loss 1.3188 | train_acc 0.687 | val_acc 0.7871 | best 0.7871 | 57.7s\n",
            "Epoch 034/100 | loss 1.3613 | train_acc 0.668 | val_acc 0.7920 | best 0.7920 | 57.1s\n",
            "Epoch 035/100 | loss 1.3391 | train_acc 0.679 | val_acc 0.7952 | best 0.7952 | 56.2s\n",
            "Epoch 036/100 | loss 1.3592 | train_acc 0.675 | val_acc 0.8003 | best 0.8003 | 57.2s\n",
            "Epoch 037/100 | loss 1.3382 | train_acc 0.687 | val_acc 0.8044 | best 0.8044 | 56.6s\n",
            "Epoch 038/100 | loss 1.3197 | train_acc 0.696 | val_acc 0.8083 | best 0.8083 | 56.4s\n",
            "Epoch 039/100 | loss 1.3137 | train_acc 0.697 | val_acc 0.8111 | best 0.8111 | 56.4s\n",
            "Epoch 040/100 | loss 1.2905 | train_acc 0.708 | val_acc 0.8146 | best 0.8146 | 56.1s\n",
            "Epoch 041/100 | loss 1.2909 | train_acc 0.711 | val_acc 0.8178 | best 0.8178 | 57.1s\n",
            "Epoch 042/100 | loss 1.3414 | train_acc 0.695 | val_acc 0.8198 | best 0.8198 | 56.8s\n",
            "Epoch 043/100 | loss 1.3068 | train_acc 0.707 | val_acc 0.8242 | best 0.8242 | 57.7s\n",
            "Epoch 044/100 | loss 1.3081 | train_acc 0.707 | val_acc 0.8278 | best 0.8278 | 57.2s\n",
            "Epoch 045/100 | loss 1.2868 | train_acc 0.712 | val_acc 0.8318 | best 0.8318 | 57.1s\n",
            "Epoch 046/100 | loss 1.2994 | train_acc 0.708 | val_acc 0.8348 | best 0.8348 | 57.7s\n",
            "Epoch 047/100 | loss 1.2289 | train_acc 0.731 | val_acc 0.8373 | best 0.8373 | 57.3s\n",
            "Epoch 048/100 | loss 1.2883 | train_acc 0.717 | val_acc 0.8402 | best 0.8402 | 56.4s\n",
            "Epoch 049/100 | loss 1.2534 | train_acc 0.730 | val_acc 0.8414 | best 0.8414 | 58.0s\n",
            "Epoch 050/100 | loss 1.2340 | train_acc 0.733 | val_acc 0.8441 | best 0.8441 | 57.9s\n",
            "Epoch 051/100 | loss 1.2078 | train_acc 0.747 | val_acc 0.8473 | best 0.8473 | 57.1s\n",
            "Epoch 052/100 | loss 1.2515 | train_acc 0.731 | val_acc 0.8493 | best 0.8493 | 57.5s\n",
            "Epoch 053/100 | loss 1.1971 | train_acc 0.754 | val_acc 0.8512 | best 0.8512 | 57.5s\n",
            "Epoch 054/100 | loss 1.2214 | train_acc 0.746 | val_acc 0.8521 | best 0.8521 | 58.6s\n",
            "Epoch 055/100 | loss 1.2297 | train_acc 0.745 | val_acc 0.8543 | best 0.8543 | 57.9s\n",
            "Epoch 056/100 | loss 1.2300 | train_acc 0.744 | val_acc 0.8555 | best 0.8555 | 57.9s\n",
            "Epoch 057/100 | loss 1.1882 | train_acc 0.759 | val_acc 0.8573 | best 0.8573 | 58.8s\n",
            "Epoch 058/100 | loss 1.1632 | train_acc 0.769 | val_acc 0.8614 | best 0.8614 | 57.2s\n",
            "Epoch 059/100 | loss 1.1879 | train_acc 0.753 | val_acc 0.8618 | best 0.8618 | 57.6s\n",
            "Epoch 060/100 | loss 1.1641 | train_acc 0.769 | val_acc 0.8629 | best 0.8629 | 57.1s\n",
            "Epoch 061/100 | loss 1.2089 | train_acc 0.758 | val_acc 0.8632 | best 0.8632 | 58.2s\n",
            "Epoch 062/100 | loss 1.1921 | train_acc 0.768 | val_acc 0.8648 | best 0.8648 | 56.9s\n",
            "Epoch 063/100 | loss 1.1989 | train_acc 0.763 | val_acc 0.8672 | best 0.8672 | 56.7s\n",
            "Epoch 064/100 | loss 1.1924 | train_acc 0.765 | val_acc 0.8697 | best 0.8697 | 57.5s\n",
            "Epoch 065/100 | loss 1.1490 | train_acc 0.775 | val_acc 0.8695 | best 0.8697 | 57.9s\n",
            "Epoch 066/100 | loss 1.1692 | train_acc 0.775 | val_acc 0.8702 | best 0.8702 | 57.2s\n",
            "Epoch 067/100 | loss 1.1177 | train_acc 0.785 | val_acc 0.8698 | best 0.8702 | 56.8s\n",
            "Epoch 068/100 | loss 1.1848 | train_acc 0.769 | val_acc 0.8714 | best 0.8714 | 58.5s\n",
            "Epoch 069/100 | loss 1.0834 | train_acc 0.799 | val_acc 0.8724 | best 0.8724 | 58.1s\n",
            "Epoch 070/100 | loss 1.1348 | train_acc 0.783 | val_acc 0.8724 | best 0.8724 | 57.9s\n",
            "Epoch 071/100 | loss 1.1702 | train_acc 0.781 | val_acc 0.8735 | best 0.8735 | 57.5s\n",
            "Epoch 072/100 | loss 1.1164 | train_acc 0.797 | val_acc 0.8737 | best 0.8737 | 58.0s\n",
            "Epoch 073/100 | loss 1.1644 | train_acc 0.779 | val_acc 0.8741 | best 0.8741 | 58.8s\n",
            "Epoch 074/100 | loss 1.1016 | train_acc 0.803 | val_acc 0.8757 | best 0.8757 | 57.3s\n",
            "Epoch 075/100 | loss 1.1130 | train_acc 0.799 | val_acc 0.8768 | best 0.8768 | 57.1s\n",
            "Epoch 076/100 | loss 1.1112 | train_acc 0.794 | val_acc 0.8777 | best 0.8777 | 58.6s\n",
            "Epoch 077/100 | loss 1.0850 | train_acc 0.801 | val_acc 0.8784 | best 0.8784 | 59.0s\n",
            "Epoch 078/100 | loss 1.0545 | train_acc 0.807 | val_acc 0.8795 | best 0.8795 | 56.8s\n",
            "Epoch 079/100 | loss 1.1037 | train_acc 0.805 | val_acc 0.8798 | best 0.8798 | 57.9s\n",
            "Epoch 080/100 | loss 1.1250 | train_acc 0.797 | val_acc 0.8803 | best 0.8803 | 57.8s\n",
            "Epoch 081/100 | loss 1.1301 | train_acc 0.797 | val_acc 0.8814 | best 0.8814 | 58.1s\n",
            "Epoch 082/100 | loss 1.0760 | train_acc 0.805 | val_acc 0.8820 | best 0.8820 | 58.1s\n",
            "Epoch 083/100 | loss 1.1023 | train_acc 0.804 | val_acc 0.8816 | best 0.8820 | 57.0s\n",
            "Epoch 084/100 | loss 1.1036 | train_acc 0.799 | val_acc 0.8821 | best 0.8821 | 59.6s\n",
            "Epoch 085/100 | loss 1.1046 | train_acc 0.804 | val_acc 0.8828 | best 0.8828 | 57.2s\n",
            "Epoch 086/100 | loss 1.1433 | train_acc 0.802 | val_acc 0.8816 | best 0.8828 | 58.5s\n",
            "Epoch 087/100 | loss 1.0801 | train_acc 0.808 | val_acc 0.8821 | best 0.8828 | 57.1s\n",
            "Epoch 088/100 | loss 1.0805 | train_acc 0.813 | val_acc 0.8828 | best 0.8828 | 58.1s\n",
            "Epoch 089/100 | loss 1.1048 | train_acc 0.805 | val_acc 0.8840 | best 0.8840 | 56.7s\n",
            "Epoch 090/100 | loss 1.0292 | train_acc 0.828 | val_acc 0.8837 | best 0.8840 | 57.1s\n",
            "Epoch 091/100 | loss 1.1100 | train_acc 0.804 | val_acc 0.8840 | best 0.8840 | 57.1s\n",
            "Epoch 092/100 | loss 1.1199 | train_acc 0.799 | val_acc 0.8836 | best 0.8840 | 57.5s\n",
            "Epoch 093/100 | loss 1.1023 | train_acc 0.807 | val_acc 0.8837 | best 0.8840 | 58.5s\n",
            "Epoch 094/100 | loss 1.0520 | train_acc 0.817 | val_acc 0.8843 | best 0.8843 | 57.4s\n",
            "Epoch 095/100 | loss 1.1214 | train_acc 0.804 | val_acc 0.8842 | best 0.8843 | 59.0s\n",
            "Epoch 096/100 | loss 1.0630 | train_acc 0.821 | val_acc 0.8841 | best 0.8843 | 57.9s\n",
            "Epoch 097/100 | loss 1.0401 | train_acc 0.825 | val_acc 0.8843 | best 0.8843 | 57.0s\n",
            "Epoch 098/100 | loss 1.0317 | train_acc 0.829 | val_acc 0.8847 | best 0.8847 | 58.5s\n",
            "Epoch 099/100 | loss 1.0619 | train_acc 0.829 | val_acc 0.8848 | best 0.8848 | 58.7s\n",
            "Epoch 100/100 | loss 1.0599 | train_acc 0.818 | val_acc 0.8848 | best 0.8848 | 58.7s\n",
            "✅ Best test accuracy: 88.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Q1: Print final accuracy\n",
        "with open(\"q1_results.json\") as f:\n",
        "    r = json.load(f)\n",
        "print(f\"Best CIFAR-10 Average Accuracy (%): {100*r['best_test_acc']:.2f}\")\n"
      ],
      "metadata": {
        "id": "EzMNu9TAw4Xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0353b7-1091-4ac6-b704-91df6df0b8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CIFAR-10 Average Accuracy (%): 88.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "esQyDSXM7FEJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}